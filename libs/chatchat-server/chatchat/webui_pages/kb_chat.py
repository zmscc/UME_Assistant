from datetime import datetime
import uuid
import openai
import streamlit as st
from streamlit_chatbox import *
from streamlit_extras.bottom_container import bottom

# ç¡®ä¿ chatchat.settings.Settings è¢«å¯¼å…¥
try:
    from chatchat.settings import Settings
except ImportError:
    # ä¸´æ—¶å…¼å®¹å¤„ç†ï¼Œé˜²æ­¢Settingsæœªè¢«å¯¼å…¥æ—¶æŠ¥é”™
    class DummySettings:
        class model_settings:
            HISTORY_LEN = 5
            TEMPERATURE = 0.7

        class kb_settings:
            DEFAULT_KNOWLEDGE_BASE = "samples"
            VECTOR_SEARCH_TOP_K = 3
            SEARCH_ENGINE_TOP_K = 3
            SCORE_THRESHOLD = 0.8
            DEFAULT_SEARCH_ENGINE = "bing"


    Settings = DummySettings

from chatchat.server.utils import get_config_models, get_config_platforms, get_default_llm, api_address
from chatchat.webui_pages.dialogue.dialogue import (save_session, restore_session, rerun,
                                                    get_messages_history, upload_temp_docs,
                                                    add_conv, del_conv, clear_conv)
from chatchat.webui_pages.utils import *

chat_box = ChatBox(
    assistant_avatar=get_img_base64("chatchat_icon_blue_square_v2.png"),
    user_avatar="ğŸ™‚"
)

'''åˆå§‹åŒ–ä¼šè¯çŠ¶æ€'''


def init_widgets():
    st.session_state.setdefault("history_len", Settings.model_settings.HISTORY_LEN)
    st.session_state.setdefault("selected_kb", Settings.kb_settings.DEFAULT_KNOWLEDGE_BASE)
    st.session_state.setdefault("kb_top_k", Settings.kb_settings.VECTOR_SEARCH_TOP_K)
    st.session_state.setdefault("se_top_k", Settings.kb_settings.SEARCH_ENGINE_TOP_K)
    st.session_state.setdefault("score_threshold", Settings.kb_settings.SCORE_THRESHOLD)
    st.session_state.setdefault("search_engine", Settings.kb_settings.DEFAULT_SEARCH_ENGINE)
    st.session_state.setdefault("return_direct", False)
    st.session_state.setdefault("cur_conv_name", chat_box.cur_chat_name)
    st.session_state.setdefault("last_conv_name", chat_box.cur_chat_name)
    st.session_state.setdefault("file_chat_id", None)


def kb_chat(api: ApiRequest):
    ctx = chat_box.context
    ctx.setdefault("uid", uuid.uuid4().hex)
    ctx.setdefault("file_chat_id", None)
    ctx.setdefault("llm_model", get_default_llm())
    ctx.setdefault("temperature", Settings.model_settings.TEMPERATURE)
    init_widgets()

    '''æ£€æŸ¥å½“å‰ä¼šè¯åç§°æ˜¯å¦å‘ç”Ÿå˜åŒ–'''
    if st.session_state.cur_conv_name != st.session_state.last_conv_name:
        save_session(st.session_state.last_conv_name)
        restore_session(st.session_state.cur_conv_name)
        st.session_state.last_conv_name = st.session_state.cur_conv_name

    @st.experimental_dialog("æ¨¡å‹é…ç½®", width="large")
    def llm_model_setting():
        # æ¨¡å‹
        cols = st.columns(3)
        platforms = ["æ‰€æœ‰"] + list(get_config_platforms())
        platform = cols[0].selectbox("é€‰æ‹©æ¨¡å‹å¹³å°", platforms, key="platform")
        llm_models = list(
            get_config_models(
                model_type="llm", platform_name=None if platform == "æ‰€æœ‰" else platform
            )
        )
        llm_models += list(
            get_config_models(
                model_type="image2text", platform_name=None if platform == "æ‰€æœ‰" else platform
            )
        )
        llm_model = cols[1].selectbox("é€‰æ‹©LLMæ¨¡å‹", llm_models, key="llm_model")
        temperature = cols[2].slider("Temperature", 0.0, 1.0, key="temperature")
        system_message = st.text_area("System Message:", key="system_message")
        if st.button("OK"):
            rerun()

    @st.experimental_dialog("é‡å‘½åä¼šè¯")
    def rename_conversation():
        name = st.text_input("ä¼šè¯åç§°")
        if st.button("OK"):
            chat_box.change_chat_name(name)
            restore_session()
            st.session_state["cur_conv_name"] = name
            rerun()

    # é…ç½®å‚æ•°
    with st.sidebar:
        st.subheader("RAG é…ç½®")
        dialogue_mode = "çŸ¥è¯†åº“é—®ç­”"  # æ¨¡å¼ç¡¬ç¼–ç 
        placeholder = st.empty()
        st.divider()

        prompt_name = "default"
        history_len = st.number_input("å†å²å¯¹è¯è½®æ•°ï¼š", 0, 20, key="history_len")
        kb_top_k = st.number_input("åŒ¹é…çŸ¥è¯†æ¡æ•°ï¼š", 1, 20, key="kb_top_k")
        ## Bge æ¨¡å‹ä¼šè¶…è¿‡1
        score_threshold = st.slider("çŸ¥è¯†åŒ¹é…åˆ†æ•°é˜ˆå€¼ï¼š", 0.0, 2.0, step=0.01, key="score_threshold")
        return_direct = st.checkbox("ä»…è¿”å›æ£€ç´¢ç»“æœ", key="return_direct")

        selected_kb = None

        def on_kb_change():
            st.toast(f"å·²åŠ è½½çŸ¥è¯†åº“ï¼š {st.session_state.selected_kb}")

        with placeholder.container():
            kb_list = [x["kb_name"] for x in api.list_knowledge_bases()]

            if not kb_list:
                st.warning("çŸ¥è¯†åº“åˆ—è¡¨ä¸ºç©ºï¼Œè¯·å…ˆå‰å¾€çŸ¥è¯†åº“ç®¡ç†é¡µé¢åˆ›å»ºæˆ–åŠ è½½çŸ¥è¯†åº“ï¼")
                selected_kb = None
            else:
                try:
                    default_index = kb_list.index(st.session_state.selected_kb)
                except:
                    default_index = 0

                selected_kb = st.selectbox(
                    "è¯·é€‰æ‹©çŸ¥è¯†åº“ï¼š",
                    kb_list,
                    index=default_index,
                    on_change=on_kb_change,
                    key="selected_kb",
                )

    # Display chat messages from history on app rerun
    chat_box.output_messages()
    chat_input_placeholder = "è¯·è¾“å…¥å¯¹è¯å†…å®¹ï¼Œæ¢è¡Œè¯·ä½¿ç”¨Shift+Enterã€‚"

    llm_model = ctx.get("llm_model")

    # chat input
    with bottom():
        cols = st.columns([1, 0.2, 15, 1])
        if cols[0].button(":gear:", help="æ¨¡å‹é…ç½®"):
            widget_keys = ["platform", "llm_model", "temperature", "system_message"]
            chat_box.context_to_session(include=widget_keys)
            llm_model_setting()

        # â­ æ¢å¤æ¸…ç©ºæŒ‰é’®
        if cols[-1].button(":wastebasket:", help="æ¸…ç©ºå¯¹è¯"):
            chat_box.reset_history()
            rerun()

        prompt = cols[2].chat_input(chat_input_placeholder, key="prompt")

    # å¦‚æœæ²¡æœ‰çŸ¥è¯†åº“è¢«é€‰ä¸­ï¼Œåˆ™ä¸è¿›è¡ŒRAGæµç¨‹
    if not selected_kb:
        return

    if prompt:
        history = get_messages_history(ctx.get("history_len", 0))
        messages = history + [{"role": "user", "content": prompt}]
        chat_box.user_say(prompt)

        extra_body = dict(
            top_k=kb_top_k,
            score_threshold=score_threshold,
            temperature=ctx.get("temperature"),
            prompt_name=prompt_name,
            return_direct=return_direct,
        )

        api_url = api_address(is_public=True)

        chat_box.use_chat_name(st.session_state.cur_conv_name)
        client = openai.Client(base_url=f"{api_url}/knowledge_base/local_kb/{selected_kb}", api_key="NONE")

        chat_box.ai_say([
            Markdown("...", in_expander=True, title="çŸ¥è¯†åº“åŒ¹é…ç»“æœ", state="running", expanded=return_direct),
            f"æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“ `{selected_kb}` ...",
        ])

        text = ""
        first = True

        '''å¤„ç†æ¥è‡ª AI æ¨¡å‹çš„æµå¼å“åº”ï¼Œå¹¶å®æ—¶æ›´æ–°èŠå¤©ç•Œé¢ä»¥æ˜¾ç¤ºæ¨¡å‹ç”Ÿæˆçš„å›ç­”ã€‚'''
        try:
            for d in client.chat.completions.create(messages=messages, model=llm_model, stream=True,
                                                    extra_body=extra_body):
                if first:
                    docs = getattr(d, 'docs', []) if hasattr(d, 'docs') else []
                    if docs:
                        chat_box.update_msg("\n\n".join(docs), element_index=0, streaming=False, state="complete")
                    else:
                        chat_box.update_msg("æœªæ‰¾åˆ°åŒ¹é…çš„çŸ¥è¯†æˆ–æ–‡æ¡£ã€‚", element_index=0, streaming=False, state="complete")

                    chat_box.update_msg("", streaming=False)
                    first = False
                    continue

                content = d.choices[0].delta.content
                if content:
                    text += content
                    chat_box.update_msg(text.replace("\n", "\n\n"), streaming=True)

            chat_box.update_msg(text, streaming=False)

        except openai.APIError as e:
            error_msg = getattr(e, 'body', str(e))
            st.error(f"çŸ¥è¯†åº“æŸ¥è¯¢ API å¤±è´¥ï¼š{error_msg}")
            chat_box.update_msg(f"æŸ¥è¯¢å¤±è´¥ï¼ŒAPI è¿”å›é”™è¯¯ï¼š{error_msg}", streaming=False)
            chat_box.update_msg("æŸ¥è¯¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œ API æœåŠ¡ã€‚", element_index=0, streaming=False, state="complete")
        except Exception as e:
            error_msg = getattr(e, 'body', str(e)) if hasattr(e, 'body') else str(e)
            st.error(f"çŸ¥è¯†åº“æŸ¥è¯¢å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{error_msg}")
            chat_box.update_msg(f"æŸ¥è¯¢å¤±è´¥ï¼Œå‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{error_msg}", streaming=False)
            chat_box.update_msg("æŸ¥è¯¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œ API æœåŠ¡ã€‚", element_index=0, streaming=False, state="complete")